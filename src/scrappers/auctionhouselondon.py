import requests
from scrappers.traceback import get_traceback
from scrappers.base_scrapper import *
from extraction_services.models import HouseAuction, ErrorReport


class AuctionHouseLondon:
    DOMAIN = 'https://auctionhouselondon.co.uk/'
    URL = 'https://auctionhouselondon.co.uk/page-data/future-auctions/page-data.json'

    def __init__(self):
        pass

    def connect_to(self, url, headers=None, payload=None):
        # print(url)
        res = requests.get(url, headers=headers, data=payload, timeout=10)
        # print(f"------ Request Response : {res.status_code} --------")
        return res

    def currency_iso_name(self, currency_symbol):
        symbols = {
            "Â£": "GBP",
            "$": "USD",
        }
        try:
            return symbols[currency_symbol]
        except:
            raise Exception(f"Currency symbol \"{currency_symbol}\" not matching with available ones.")

    def parser(self, data):
        for json_data in data['result']['pageContext']['auctions']:
            for lot_details in json_data['Lots']:
                try:
                    if not lot_details:
                        pass
                    if not 'Sold Prior' in lot_details['GuidePrice']:
                        price, currency = prepare_price(lot_details['GuidePrice'])
                    else:
                        price = 0.0
                        currency = ''
                    full_address = lot_details['FullAddress']
                    url_id = "-".join(full_address.replace(',', '').split())
                    lot_id = lot_details['ID']
                    url = f"https://auctionhouselondon.co.uk/page-data/lot/{url_id}-{lot_id}/page-data.json".lower()
                    inner_res = self.connect_to(url)
                    try:
                        inner_details = inner_res.json()['result']['pageContext']
                    except:
                        continue
                    auction_date = dateparser.parse(inner_details['AuctionDate'])
                    data_hash = {
                        # "_id": lot_id,
                        "price": price,
                        "currency_type": currency,
                        "picture_link": lot_details['Thumbnail'],
                        "property_description": inner_details['Description'],
                        "property_link": url.replace('page-data.json', '').replace('/page-data', ''),
                        "address": full_address,
                        "postal_code": lot_details['PostCode'],
                        "number_of_bedrooms": inner_details['Bedrooms'],
                        "property_type": inner_details['PropertyType'],
                        "tenure": inner_details['TenureType'],
                        "auction_datetime": auction_date,
                        "auction_venue": None,
                        "source": "auctionhouselondon.co.uk"
                    }
                    HouseAuction.sv_upd_result(data_hash)
                except BaseException as be:
                    save_error_report(be, __file__)
                    # _traceback = get_traceback()
                    # if error_report := ErrorReport.objects.filter(trace_back=_traceback).first():
                    #     error_report.count = error_report.count + 1
                    #     error_report.save()
                    # else:
                    #     ErrorReport.objects.create(file_name="auctionhouselondon.py", error=str(be),
                    #                                trace_back=_traceback)

    def scraper(self):
        response = self.connect_to(self.URL)
        data = load_json(response.content)
        self.parser(data)


def run():
    AuctionHouseLondon().scraper()
